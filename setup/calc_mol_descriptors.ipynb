{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db1879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import time\n",
    "import csv\n",
    "import sys\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Descriptors3D\n",
    "from rdkit.Chem import Descriptors, MolFromSmiles\n",
    "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf368eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_headers(csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # Read the first row\n",
    "        first_row = next(reader, None)\n",
    "        if first_row:\n",
    "            # Count the number of fields in the first row\n",
    "            num_headers = len(first_row)\n",
    "            return num_headers\n",
    "        else:\n",
    "            # File is empty or has no headers\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf45c1-328a-4f69-88ed-917f6b40fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_row_lengths(csv_file):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        \n",
    "        # Read the header row\n",
    "        headers = next(reader, None)\n",
    "        if headers is None:\n",
    "            # No headers found\n",
    "            return False\n",
    "        \n",
    "        num_headers = len(headers)\n",
    "        \n",
    "        # Iterate through the remaining rows\n",
    "        for row in reader:\n",
    "            if len(row) != num_headers:\n",
    "                # Row length doesn't match the number of headers\n",
    "                return False\n",
    "                \n",
    "    # All rows have the same length as headers\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef8b2dd",
   "metadata": {},
   "source": [
    "I had a file of 3D conformers for all compounds in library (all_1conf.sdf). Decided to use this to calculate the ecfp=Morgan fingerprints. However, technically all you need is the SMILES of the compounds (binders_docking.csv), see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f2548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the input SDF file with conformers\n",
    "sdf_file_path = 'all_1conf.sdf'\n",
    "suppl = Chem.SDMolSupplier(sdf_file_path)\n",
    "\n",
    "# Initialize lists to store names, SMILES, and ECFP fingerprints\n",
    "names_list = []\n",
    "smiles_list = []\n",
    "ecfp4_list = []\n",
    "\n",
    "# Iterate through each molecule in the SDF file\n",
    "for mol in suppl:\n",
    "    if mol is not None:\n",
    "        # Extract name and SMILES from the SDF data fields\n",
    "        name = mol.GetProp('_Name')\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        \n",
    "        # Calculate ECFP4 fingerprints\n",
    "        # All 3 of the publications I read had either 2, 3, or 4 radius so I will go with 3\n",
    "        ecfp4_fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=2048)\n",
    "        \n",
    "        # Append data to lists\n",
    "        names_list.append(name)\n",
    "        smiles_list.append(smiles)\n",
    "        ecfp4_list.append(ecfp4_fingerprint)\n",
    "\n",
    "# Convert ECFP fingerprints to binary digits\n",
    "ecfp4_binary_digits = [list(ecfp4_fingerprint.ToBitString()) for ecfp4_fingerprint in ecfp4_list]\n",
    "\n",
    "# Save ECFP4 fingerprints, names, and SMILES to a CSV file\n",
    "output_file_path = 'all_ecfp4.csv'\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header\n",
    "    header = [\"Name\", \"SMILES\", ] + [f\"Morgan_bit{i}\" for i in range(2048)]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Write data\n",
    "    for names, smiles, fingerprint in zip(names_list, smiles_list, ecfp4_binary_digits):\n",
    "        writer.writerow([names, smiles] + fingerprint)\n",
    "\n",
    "print(f\"ECFP4 fingerprints, names, and SMILES saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c7edd-f8ae-446b-96ed-3fdd90345dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smiles_to_ecfp4(smiles_list, radius=3, nBits=2048):\n",
    "    ecfp4_list = []\n",
    "    for smiles in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            ecfp4_fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=nBits)\n",
    "            ecfp4_list.append(ecfp4_fingerprint)\n",
    "    return ecfp4_list\n",
    "\n",
    "# Read input CSV file with SMILES strings\n",
    "csv_file_path = '7nsw_all_hybrid.csv'\n",
    "smiles_data = {'Name': [], 'SMILES': []}\n",
    "with open(csv_file_path, 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    header = next(reader)  # Skip header\n",
    "    for row in reader:\n",
    "        smiles_data['Name'].append(row[0])  # Assuming the Name column is the first column\n",
    "        smiles_data['SMILES'].append(row[1])  # Assuming the SMILES column is the second column\n",
    "\n",
    "# Calculate ECFP4 fingerprints\n",
    "ecfp4_list = smiles_to_ecfp4(smiles_data['SMILES'])\n",
    "\n",
    "# Convert ECFP fingerprints to binary digits\n",
    "ecfp4_binary_digits = [list(ecfp4_fingerprint.ToBitString()) for ecfp4_fingerprint in ecfp4_list]\n",
    "\n",
    "# Save ECFP4 fingerprints, names, and SMILES to a CSV file\n",
    "output_file_path = 'output_ecfp4.csv'\n",
    "with open(output_file_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # Write header\n",
    "    header = [\"Name\", \"SMILES\"] + [f\"Morgan_bit{i}\" for i in range(2048)]\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Write data\n",
    "    for names, smiles, fingerprint in zip(smiles_data['Name'], smiles_data['SMILES'], ecfp4_binary_digits):\n",
    "        writer.writerow([names, smiles] + fingerprint)\n",
    "\n",
    "print(f\"ECFP4 fingerprints, names, and SMILES saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076e09a-66c4-4a5a-b4b1-b29026f32f8b",
   "metadata": {},
   "source": [
    "I need to remove the compounds that did not actually dock successfully. I realized after I calculated descriptors for ALL 45,000 compounds that I should have first docked them all and then taken the ones that docked successfully to calculate the descriptors.\n",
    "\n",
    "Note: This would only be useful in this specific case since we have the possibility to dock ALL compounds in order to have the ground truth. For free energy calculations we will not be able to do this and we would need to have all descriptors pre-calculated. PLUS we only have to do this once, at the beginning of the project when we calculate descriptors for the entire library of compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9b5dc-be02-481a-a3bb-83da0ce7445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_docked_cmpds(file1, file2, docked_output_file, unsuccessful_output_file):\n",
    "    # Read the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Identify common compounds only in the second DataFrame\n",
    "    docked_compounds = pd.merge(df1[['Name']], df2, on='Name', how='inner')\n",
    "    unsuccessful_compounds = df2[~df2['Name'].isin(docked_compounds['Name'])]\n",
    "\n",
    "    # Save the results to new CSV files\n",
    "    docked_compounds.to_csv(docked_output_file, index=False)\n",
    "    unsuccessful_compounds.to_csv(unsuccessful_output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20ed7b-301b-469c-bd28-86a24c719c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace '7nsw_all_hybrid.csv', 'all_ecfp4.csv', 'docked_ecfp.csv', and 'unsuccessful_ecfp.csv'\n",
    "# with your actual file names.\n",
    "filter_docked_cmpds('7nsw_all_hybrid.csv', 'all_ecfp4.csv', 'docked_ecfp.csv', 'unsuccessful_docked_ecfp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de188ab7",
   "metadata": {},
   "source": [
    "Moving forward we will be using the docked_ecfp.csv descriptor file and not the all_ecfp4.csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e0789",
   "metadata": {},
   "source": [
    "Create a binders file which would be the top 2000 compounds based on most negative docking scores. These will be the \"actives\" in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198bb4f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the binders/actives file\n",
    "csv_file_path = '7nsw_all_hybrid.csv'\n",
    "\n",
    "# Load the data from CSV\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Sort the DataFrame based on the \"Score\" column in ascending order\n",
    "sorted_data = data.sort_values(by='Score', ascending=True)\n",
    "\n",
    "# Select the top 2000 compounds\n",
    "binders = sorted_data.head(2000)\n",
    "\n",
    "# Save the selected compounds to a new CSV file\n",
    "output_csv_path = 'binders_docking.csv'\n",
    "binders.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f'Active compound list saved to {output_csv_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1 (main, Dec  3 2024, 17:59:52) [Clang 16.0.0 (clang-1600.0.26.4)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
